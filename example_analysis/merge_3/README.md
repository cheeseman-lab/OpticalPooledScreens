# merge_3

This module provides a workflow for aligning and merging phenotype microscopy data with sequencing-by-synthesis (SBS) data. It uses triangle hashing algorithms for robust point matching between different imaging modalities.

## Contents

1. `merge_3_smk_test.ipynb`: Jupyter notebook for testing alignment parameters and visualizing results
2. `merge_3.smk`: Main Snakemake file for merging aligned phenotype and SBS data
3. `hash_3.smk`: Snakemake file for generating hash alignments
4. `merge_3.sh`: Bash script to execute the complete workflow
5. `merge_3_eval.py`: Python script for collating alignment and phenotype data, filtering, and generating quality control plots.

## Usage

1. Test input patterns and processing:
   - Run `merge_3_smk_test.ipynb` to visualize alignment quality, test matching parameters, and verify initial site selection.
   - Modify the input patterns, filtering criteria, and other parameters as needed for your specific setup.

2. Run phenotype processing workflow:
   - Adjust the parameters in `hash_3.smk` and `merge_3.smk` based on your specific setup and requirements.
   - Execute `merge_3.sh` to run the Snakemake workflow of both of these files.

3. Evaluate results:
   - Run `merge_3_eval.py`, which collates the final single-cell data and generates quality control plots and statistics for the alignment results.

## Key Features

- Performs triangle-hashing to find matches between images of different magnifications
- Merges SBS and phenotyping data at the tile and cell level
- Merges the entire dataset of CellProfiler features with barcode information
- Generates quality control plots and statistics

## Dependencies

- Python libraries: numpy, pandas, matplotlib, seaborn
- ops package modules:
  - ops.firesnake: For wrappers used in the Snakemake workflow
      - ops.triangle_hash: For triangle-based point matching
  - ops.qc and ops.merge_utils: For quality control functions and downstream processing

## Notes

Given different formats of saving data in either a well based (single or multichannel) or tile based (multichannel) format, we provide example analysis for the two respective cases. For this step, there is no difference in these workflows.

- Ensure input files exist in the correct directories before running the workflow
- The determinant range should be adjusted based on:
  - Objective magnifications (e.g., 20X vs 10X)
  - Camera binning settings
  - Expected variation in alignment
- Initial sites should be carefully chosen to represent well-distributed points across the imaging area
- Before running the full workflow, it is recommended to test the pipeline on these initial alignments using `merge_3_smk_test.ipynb`.

## File structure for running

```
plate/
├── merge_3.smk
├── hash_3.smk
├── process_ph/
│   └── tables/ 
├── process_sbs/
│   └── tables/ 
└── merge_3/
│   ├── merge_3_smk_test.ipynb
│   ├── merge_3.sh
│   ├── merge_3_eval.py
│   ├── merge_3_eval.sh
│   ├── hdf/*
└── alignment/*
```

Directories marked with an asterisk contain files generated by this workflow.

Note: 
- Ensure that your input files from the previous processing steps are in the `process_ph/tables/` and `process_sbs/tables/` directories before running the workflow.
- The test workflow (`merge_3_smk_test.ipynb`) will help visualize and validate alignment parameters for your initial sites.
- The Snakemake workflows will generate:
   - Fast alignment files in `merge_3/hdf/`
   - Merged alignment files in `alignment/`
   - Final merged dataset in `merge_3/hdf/`

Maintaining this file structure is crucial for the correct execution of the workflow. Any changes to the structure may require corresponding adjustments in the scripts.