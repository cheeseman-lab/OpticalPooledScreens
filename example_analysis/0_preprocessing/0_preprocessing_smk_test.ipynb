{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing SMK Test\n",
    "\n",
    "This notebook should be used as a test for ensuring correct SBS/phenotype image preprocessing.\n",
    "Cells marked with `SET PARAMETERS` contain crucial variables that need to be set according to your specific experimental setup and data organization.\n",
    "Please review and modify these variables as needed before proceeding with the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from ops.preprocessing_smk import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input/sbs/P001_SBS_10x_C1_Wells-A1_Points-001__Channel_Cy7,Cy5,AF594,Cy3_SBS,DAPI_SBS.nd2',\n",
       " 'input/sbs/P001_SBS_10x_C1_Wells-A1_Points-100__Channel_Cy7,Cy5,AF594,Cy3_SBS,DAPI_SBS.nd2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SBS_INPUT_PATTERN_METADATA = \"input/sbs/*C{cycle}_Wells-{well}_Points-*__Channel*.nd2\"\n",
    "files_list = glob.glob(\n",
    "    SBS_INPUT_PATTERN_METADATA.format(\n",
    "        cycle=1, well=\"A1\"\n",
    "    )\n",
    ")\n",
    "files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_data</th>\n",
       "      <th>y_data</th>\n",
       "      <th>z_data</th>\n",
       "      <th>pfs_offset</th>\n",
       "      <th>field_of_view</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33049.0</td>\n",
       "      <td>-35283.0</td>\n",
       "      <td>3139.66</td>\n",
       "      <td>8063</td>\n",
       "      <td>1</td>\n",
       "      <td>input/sbs/P001_SBS_10x_C1_Wells-A1_Points-001_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34602.4</td>\n",
       "      <td>-26403.1</td>\n",
       "      <td>3125.04</td>\n",
       "      <td>8063</td>\n",
       "      <td>100</td>\n",
       "      <td>input/sbs/P001_SBS_10x_C1_Wells-A1_Points-100_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x_data   y_data   z_data  pfs_offset  field_of_view  \\\n",
       "0  33049.0 -35283.0  3139.66        8063              1   \n",
       "1  34602.4 -26403.1  3125.04        8063            100   \n",
       "\n",
       "                                            filename  \n",
       "0  input/sbs/P001_SBS_10x_C1_Wells-A1_Points-001_...  \n",
       "1  input/sbs/P001_SBS_10x_C1_Wells-A1_Points-100_...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARSE_FUNCTION_HOME = \"input\"\n",
    "PARSE_FUNCTION_DATASET = \"example_dataset\"\n",
    "Snake_preprocessing._extract_metadata_tile(\n",
    "    files_list, \n",
    "    parse_function_home=PARSE_FUNCTION_HOME,\n",
    "    parse_function_dataset=PARSE_FUNCTION_DATASET,\n",
    "    parse_function_tiles=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_parse_file(parse_function_home, parse_function_dataset, pattern, well, cycle, tiles=None):\n",
    "    if tiles == None:\n",
    "        filled_pattern = pattern.format(cycle=cycle, well=well)\n",
    "        # Find files matching the pattern\n",
    "        matching_files = glob.glob(filled_pattern)\n",
    "        \n",
    "        if matching_files:\n",
    "            # Select the first matching file\n",
    "            print(f\"Found files to parse: {matching_files}\")\n",
    "            \n",
    "            # Parse the file\n",
    "            try:\n",
    "                file_to_parse = matching_files[0]\n",
    "                file_description = parse_file(file_to_parse, home=parse_function_home, dataset=parse_function_dataset)\n",
    "                print(f\"File description for first file: {file_description}\")\n",
    "                print(\"-\" * 50)\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing file for tile {tile}: {e}\")\n",
    "        else:\n",
    "            print(f\"No files found matching pattern for tile {tile}: {filled_pattern}\")\n",
    "\n",
    "        return\n",
    "    \n",
    "    for tile in tiles:\n",
    "        # Replace placeholders in the pattern\n",
    "        filled_pattern = pattern.format(cycle=cycle, well=well, tile=f\"{tile:03d}\")\n",
    "        \n",
    "        # Find files matching the pattern\n",
    "        matching_files = glob.glob(filled_pattern)\n",
    "        \n",
    "        if matching_files:\n",
    "            # Select the first matching file\n",
    "            print(f\"Found files to parse: {matching_files}\")\n",
    "            \n",
    "            # Parse the file\n",
    "            try:\n",
    "                file_to_parse = matching_files[0]\n",
    "                file_description = parse_file(file_to_parse, home=parse_function_home, dataset=parse_function_dataset)\n",
    "                print(f\"File description for tile {tile}: {file_description}\")\n",
    "                print(\"-\" * 50)\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing file for tile {tile}: {e}\")\n",
    "        else:\n",
    "            print(f\"No files found matching pattern for tile {tile}: {filled_pattern}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET PARAMETERS\n",
    "\n",
    "### Check if file patterns are according to plan\n",
    "\n",
    "- `PARSE_FUNCTION_HOME` and `PARSE_FUNCTION_DATASET`: The base directory and dataset name for the parsing function.\n",
    "- `SBS_INPUT_PATTERN_METADATA` and `PH_INPUT_PATTERN_METADATA`: The file naming conventions and directory structures for SBS and PH images without respect to tile. These images are used across tiles to compile metadata.\n",
    "- `SBS_INPUT_PATTERN` and `PH_INPUT_PATTERN`: The file naming conventions and directory structures for SBS and PH images.\n",
    "\n",
    "Ensure these variables accurately reflect your experimental setup to guarantee correct data processing and analysis.\n",
    "\n",
    "Acceptable ND2 File Format:\n",
    "The parsing functions expect ND2 files to follow these naming conventions:\n",
    "1. Cycle information (for SBS only) should be in a subdirectory named '/c{number}/' in the file path.\n",
    "2. Well information should be present as 'Wells-XX_' or 'WellXX_' in the filename.\n",
    "3. For multi-tile experiments, tile information should be present as 'Points-####' in the filename.\n",
    "4. Channel information should be present as 'Channel{name}_' in the filename.\n",
    "5. Phenotype images should have 'input_ph' in the file path.\n",
    "6. SBS images should have 'input_sbs' in the file path.\n",
    "\n",
    "Example acceptable filenames:\n",
    "- SBS: /lab/example/screens/dataset/input_sbs/c1/acquisition_date_folder/Wells-A1_Points-0001_ChannelDAPI_Seq0000.nd2\n",
    "- PH:  /lab/example/screens/dataset/input_ph/acquisition_date_folder/Wells-A1_Points-0001_ChannelDAPI_Seq0000.nd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SBS_INPUT_PATTERN_METADATA:\n",
      "Found files to parse: ['input/sbs/P001_SBS_10x_C1_Wells-A1_Points-001__Channel_Cy7,Cy5,AF594,Cy3_SBS,DAPI_SBS.nd2', 'input/sbs/P001_SBS_10x_C1_Wells-A1_Points-100__Channel_Cy7,Cy5,AF594,Cy3_SBS,DAPI_SBS.nd2']\n",
      "File description for first file: {'home': 'input', 'dataset': 'example_dataset', 'ext': 'tif', 'well': 'A1'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Testing PH_INPUT_PATTERN_METADATA:\n",
      "Found files to parse: ['input/ph/P001_Pheno_20x_Wells-A1_Points-100__Channel_AF750,Cy3,GFP,DAPI.nd2', 'input/ph/P001_Pheno_20x_Wells-A1_Points-001__Channel_AF750,Cy3,GFP,DAPI.nd2']\n",
      "File description for first file: {'home': 'input', 'dataset': 'example_dataset', 'ext': 'tif', 'well': 'A1'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Testing SBS_INPUT_PATTERN:\n",
      "Found files to parse: ['input/sbs/P001_SBS_10x_C1_Wells-A1_Points-001__Channel_Cy7,Cy5,AF594,Cy3_SBS,DAPI_SBS.nd2']\n",
      "File description for tile 1: {'home': 'input', 'dataset': 'example_dataset', 'ext': 'tif', 'well': 'A1'}\n",
      "--------------------------------------------------\n",
      "Found files to parse: ['input/sbs/P001_SBS_10x_C1_Wells-A1_Points-100__Channel_Cy7,Cy5,AF594,Cy3_SBS,DAPI_SBS.nd2']\n",
      "File description for tile 100: {'home': 'input', 'dataset': 'example_dataset', 'ext': 'tif', 'well': 'A1'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Testing PH_INPUT_PATTERN:\n",
      "Found files to parse: ['input/ph/P001_Pheno_20x_Wells-A1_Points-001__Channel_AF750,Cy3,GFP,DAPI.nd2']\n",
      "File description for tile 1: {'home': 'input', 'dataset': 'example_dataset', 'ext': 'tif', 'well': 'A1'}\n",
      "--------------------------------------------------\n",
      "Found files to parse: ['input/ph/P001_Pheno_20x_Wells-A1_Points-100__Channel_AF750,Cy3,GFP,DAPI.nd2']\n",
      "File description for tile 100: {'home': 'input', 'dataset': 'example_dataset', 'ext': 'tif', 'well': 'A1'}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Parse function parameters\n",
    "PARSE_FUNCTION_HOME = \"input\"\n",
    "PARSE_FUNCTION_DATASET = \"example_dataset\"\n",
    "\n",
    "# File patterns for SBS and PH images with placeholders (find all tiles to compile metadata)\n",
    "SBS_INPUT_PATTERN_METADATA = 'input/sbs/*C{cycle}_Wells-{well}_Points-*__Channel*.nd2'\n",
    "PH_INPUT_PATTERN_METADATA = 'input/ph/*Wells-{well}_Points-*__Channel*.nd2'\n",
    "\n",
    "# File patterns for SBS and PH images\n",
    "SBS_INPUT_PATTERN = 'input/sbs/*C{cycle}_Wells-{well}_Points-{tile:0>3}__Channel*.nd2'\n",
    "PH_INPUT_PATTERN = 'input/ph/*Wells-{well}_Points-{tile:0>3}__Channel*.nd2'\n",
    "# phenotpye example files too large to be included on GitHub\n",
    "\n",
    "# Test SBS_INPUT_PATTERN_METADATA\n",
    "print(\"Testing SBS_INPUT_PATTERN_METADATA:\")\n",
    "sbs_parsed = find_and_parse_file(PARSE_FUNCTION_HOME, PARSE_FUNCTION_DATASET, SBS_INPUT_PATTERN_METADATA, well='A1', cycle=1)\n",
    "\n",
    "# Test PH_INPUT_PATTERN_METADATA\n",
    "print(\"\\nTesting PH_INPUT_PATTERN_METADATA:\")\n",
    "sbs_parsed = find_and_parse_file(PARSE_FUNCTION_HOME, PARSE_FUNCTION_DATASET, PH_INPUT_PATTERN_METADATA, well='A1', cycle=1)\n",
    "\n",
    "# Test SBS_INPUT_PATTERN\n",
    "print(\"\\nTesting SBS_INPUT_PATTERN:\")\n",
    "sbs_parsed = find_and_parse_file(PARSE_FUNCTION_HOME, PARSE_FUNCTION_DATASET, SBS_INPUT_PATTERN, well='A1', cycle=1, tiles=[1, 100])\n",
    "\n",
    "# Test PH_INPUT_PATTERN\n",
    "print(\"\\nTesting PH_INPUT_PATTERN:\")\n",
    "ph_parsed = find_and_parse_file(PARSE_FUNCTION_HOME, PARSE_FUNCTION_DATASET, PH_INPUT_PATTERN, well='A1', cycle=None, tiles=[1, 100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ops_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
